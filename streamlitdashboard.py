#-*- coding: utf-8 -*-
#   Author : Dr. Songhee Kang.
#   Email : dellabee@tukorea.ac.kr
#   Description : KOSTEC stat visualizer
#   Version : 1.0.0
#   History : 1.0.0 - 2025. 04. 29. ìµœì´ˆ ì‘ì„±

import streamlit as st
import pandas as pd
import json
import altair as alt
import networkx as nx
from pyvis.network import Network
import streamlit.components.v1 as components
import os

st.set_page_config(page_title="ğŸ“ˆ í‚¤ì›Œë“œ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸ“ˆ ì£¼ê°„ í‚¤ì›Œë“œ ëŒ€ì‹œë³´ë“œ")

# ì‚¬ì´ë“œë°”: í‚¤ì›Œë“œ, ìŠ¤ëƒ…ìƒ· ì„ íƒ
keywords = ['AI', 'ê³¼í•™ê¸°ìˆ ì •ì±…']
snapshot_dates = ['2025-04-07', '2025-04-14', '2025-04-21', '2025-04-28']

selected_keyword = st.sidebar.selectbox("ê´€ì‹¬ í‚¤ì›Œë“œ", keywords)
selected_snapshot = st.sidebar.selectbox("ìŠ¤ëƒ…ìƒ· ë‚ ì§œ", snapshot_dates)

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
keyword_prefix = 'AI' if selected_keyword == 'AI' else 'STP'
report_path = f"assets/reports/{keyword_prefix}_{selected_snapshot}.json"
trend_path = f"assets/data/{keyword_prefix}_{selected_snapshot}_KT.json"

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_report(path):
    with open(path, encoding='utf-8') as f:
        return json.load(f)

try:
    report = load_report(report_path)
except FileNotFoundError:
    st.error("ë³´ê³ ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ì¹´ë“œ ìŠ¤íƒ€ì¼ ì ìš©
with st.container():
    st.markdown("### ğŸ“Š ëŒ€ì‹œë³´ë“œ ì˜ì—­")

    tabs = st.tabs(["ğŸ“ˆ í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜", "ğŸ•¸ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬", "ğŸ” ì—°ê´€ì–´ í†µê³„", "ğŸ† Top 20 í‚¤ì›Œë“œ"])

    # 1. ë¹ˆë„ìˆ˜
    with tabs[0]:
        st.subheader("ğŸ“ˆ í‚¤ì›Œë“œë³„ ë¹ˆë„ìˆ˜ í†µê³„")
        st.divider()
        freq_df = pd.DataFrame(report["frequency_stats"])
        st.dataframe(freq_df, use_container_width=True)

        st.subheader("ğŸ“ˆ íŠ¸ë Œë“œ ì°¨íŠ¸")
        try:
            trend_data = pd.read_json(trend_path)
            chart = alt.Chart(trend_data).mark_line(point=True).encode(
                x='date:T',
                y=alt.Y('count:Q', title='ë¹ˆë„ìˆ˜'),
                color='keyword:N'
            )
            st.altair_chart(chart, use_container_width=True)
        except Exception as e:
            st.error(f"íŠ¸ë Œë“œ ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")

    # 2. ë„¤íŠ¸ì›Œí¬
    with tabs[1]:
        st.subheader("ğŸ•¸ í‚¤ì›Œë“œ ë™ì‹œì¶œí˜„ ë„¤íŠ¸ì›Œí¬")
        st.divider()
        try:
            G = nx.Graph()
            for link in report["co_occurrence_network"]:
                G.add_edge(link['source'], link['target'], weight=link['weight'])
            net = Network(height="500px", width="100%", bgcolor="#ffffff", font_color="black")
            net.from_nx(G)
            net.save_graph("network.html")
            components.iframe("network.html", height=550)
        except Exception as e:
            st.error(f"ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ë¡œë”© ì‹¤íŒ¨: {e}")

    # 3. ì—°ê´€ì–´ í†µê³„
    with tabs[2]:
        st.subheader("ğŸ” í‚¤ì›Œë“œ ì—°ê´€ì–´ í†µê³„")
        st.divider()
        for assoc in report["associations"]:
            st.markdown(f"ğŸ”¹ **{assoc['term']}** ({assoc['count']}íšŒ)")

    # 4. Top 20 í‚¤ì›Œë“œ
    with tabs[3]:
        st.subheader("ğŸ† Top 20 í‚¤ì›Œë“œ")
        st.divider()
        for item in report["top_keywords"]:
            with st.expander(f"**{item['rank']}. {item['keyword']}** (ì‚¬ì´íŠ¸ {item['site_coverage']}ê°œ, {item['site_count']}íšŒ)"):
                for url in item.get('sites', []):
                    st.markdown(f"- [ğŸ”— {url}]({url})")

