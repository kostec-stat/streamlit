#-*- coding: utf-8 -*-
#   Author : Dr. Songhee Kang.
#   Email : dellabee@tukorea.ac.kr
#   Description : KOSTEC stat visualizer
#   Version : 1.0.0
#   History : 1.0.0 - 2025. 04. 29. ìµœì´ˆ ì‘ì„±

# streamlit_dashboard.py

import streamlit as st
import pandas as pd
import json
import altair as alt
import networkx as nx
from pyvis.network import Network
import streamlit.components.v1 as components
import os

# í‚¤ì›Œë“œ, ìŠ¤ëƒ…ìƒ· ë‚ ì§œ ë¦¬ìŠ¤íŠ¸
keywords = []
# 1. í‚¤ì›Œë“œ ë¡œë”©
def load_keywords(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        keywords = [line.strip() for line in f if line.strip()]
    return keywords

keywords = load_keywords("assets/input/keywords.txt")  # í‚¤ì›Œë“œ íŒŒì¼ ê²½ë¡œ ìˆ˜ì •
snapshot_dates = ['20250429']

# Streamlit App ì‹œì‘
st.set_page_config(page_title="ğŸ“ˆ í‚¤ì›Œë“œ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸ“ˆ ì£¼ê°„ í‚¤ì›Œë“œ ëŒ€ì‹œë³´ë“œ")

# ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œì™€ ë‚ ì§œ ì„ íƒ
selected_keyword = st.sidebar.selectbox("ê´€ì‹¬ í‚¤ì›Œë“œ ì„ íƒ", keywords)
selected_snapshot = st.sidebar.selectbox("ìŠ¤ëƒ…ìƒ· ë‚ ì§œ ì„ íƒ", snapshot_dates)

# ì„ íƒì— ë”°ë¼ JSON íŒŒì¼ ê²½ë¡œ ê²°ì •
report_path = f"assets/reports/{selected_keyword}_{selected_snapshot}.json"
trend_path = f"assets/data/{selected_snapshot}_trend_summary.json"

# ë°ì´í„° ë¡œë”©
@st.cache_data
def load_report(path):
    with open(path, encoding='utf-8') as f:
        return json.load(f)

try:
    report = load_report(report_path)
except FileNotFoundError:
    st.error("ë³´ê³ ì„œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# íƒ­ ìƒì„±
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜", "ğŸ•¸ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬", "ğŸ” ì—°ê´€ì–´ í†µê³„", "ğŸ† Top 20 í‚¤ì›Œë“œ"])

# 1. í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ í†µê³„
with tab1:
    st.subheader("ğŸ“Š í‚¤ì›Œë“œë³„ ë¹ˆë„ìˆ˜ í†µê³„")
    
    freq_df = pd.DataFrame(report["frequency_stats"])
    st.dataframe(freq_df)
    
    st.subheader("ğŸ“ˆ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ì°¨íŠ¸")
    try:
        trend_data = pd.read_json(trend_path)
        chart = alt.Chart(trend_data).mark_line(point=True).encode(
            x='date:T',
            y=alt.Y('count:Q', title='ë¹ˆë„ìˆ˜'),
            color='keyword:N'
        )
        st.altair_chart(chart, use_container_width=True)
    except Exception as e:
        st.error(f"íŠ¸ë Œë“œ ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")

# 2. í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬
with tab2:
    st.subheader("ğŸ•¸ í‚¤ì›Œë“œ ë™ì‹œì¶œí˜„ ë„¤íŠ¸ì›Œí¬")
    try:
        G = nx.Graph()
        for link in report["co_occurrence_network"]:
            G.add_edge(link['source'], link['target'], weight=link['weight'])
        
        net = Network(height="500px", width="100%", bgcolor="#ffffff", font_color="black")
        net.from_nx(G)
        net.save_graph("network.html")
        components.iframe("network.html", height=550)
    except Exception as e:
        st.error(f"ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ë¡œë”© ì‹¤íŒ¨: {e}")

# 3. ì—°ê´€ì–´ í†µê³„
with tab3:
    st.subheader("ğŸ” í‚¤ì›Œë“œ ì—°ê´€ì–´ í†µê³„")
    for assoc in report["associations"]:
        st.write(f"ğŸ”¹ {assoc['term']} ({assoc['count']}íšŒ)")

# 4. Top 20 í‚¤ì›Œë“œ
with tab4:
    st.subheader("ğŸ† Top 20 í‚¤ì›Œë“œ ë° ì‚¬ì´íŠ¸ ëª©ë¡")
    for item in report["top_keywords"]:
        with st.expander(f"{item['rank']}. {item['keyword']} (ì‚¬ì´íŠ¸ {item['site_coverage']}ê°œ, {item['site_count']}íšŒ)"):
            for url in item.get('sites', []):
                st.markdown(f"- [ğŸ”— {url}]({url})")
