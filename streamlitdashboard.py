# -*- coding: utf-8 -*-
# Author : Dr. Songhee Kang
# Description : KOSTEC stat visualizer

import streamlit as st
import pandas as pd
import json
import altair as alt
import networkx as nx
from streamlit_agraph import agraph, Node, Edge, Config
import os
from collections import defaultdict

# --- 1. ì„¤ì • (ê°€ì¥ ë¨¼ì €)
st.set_page_config(page_title="ğŸ“ˆ í•œì¤‘ê³¼ê¸°í˜‘ë ¥ì„¼í„° í‚¤ì›Œë“œ ëŒ€ì‹œë³´ë“œ", layout="wide")
# --- 2. CSS ì ìš©
def local_css(file_name):
    with open(file_name, "r", encoding="utf-8") as f:
        css_content = f.read()
    st.markdown(f"<style>{css_content}</style>", unsafe_allow_html=True)

# assets/css í´ë”ì˜ main.cssë¥¼ ì½ì–´ì˜¤ê¸°
local_css("assets/css/main.css")
# --- 3. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
def load_keywords(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]

def load_json(path):
    with open(path, encoding='utf-8-sig') as f:
        return json.load(f)

# í‚¤ì›Œë“œ, ìŠ¤ëƒ…ìƒ· ë‚ ì§œ
keywords = load_keywords("assets/input/keywords.txt")
snapshot_dates = ['20250429', '20250501', '20250511']

# --- 4. ì‚¬ì´ë“œë°”
selected_keyword = st.sidebar.selectbox("ê´€ì‹¬ í‚¤ì›Œë“œ ì„ íƒ", keywords)
selected_snapshot = st.sidebar.selectbox("ìŠ¤ëƒ…ìƒ· ë‚ ì§œ ì„ íƒ", snapshot_dates)
summary_type = st.sidebar.selectbox("ì£¼ê¸°ë³„ ìš”ì•½ ë³´ê³ ì„œ ì„ íƒ", ["ì „ì²´",  "ì—°ê°„", "ì£¼ê°„"], index=0)

# --- 5. ë©”ì¸ ëŒ€ì‹œë³´ë“œ
st.title("ğŸ“ˆ í‚¤ì›Œë“œ ëŒ€ì‹œë³´ë“œ")
    
# --- 6-1. ë°ì´í„° ê²½ë¡œ ì„¤ì •
report_path = f"assets/reports/{selected_keyword}_{selected_snapshot}.json"
trend_path = f"assets/data/{snapshot_dates[-1]}_trend_summary.json"
search_results_path = f"assets/data/{selected_snapshot}_search_results.csv"

# --- 6-2. ë°ì´í„° ë¡œë”©
try:
    report = load_json(report_path)
except FileNotFoundError:
    st.error(f"ë³´ê³ ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {report_path}")
    st.stop()

try:
    trend_json = load_json(trend_path)
    trend_data = pd.DataFrame(trend_json["trend_data"])
    trend_data["date"] = pd.to_datetime(trend_data["date"])  # ë‚ ì§œ í˜•ì‹ ë³€í™˜
    # 4. ì´ ë¹ˆë„ìˆ˜ í•©ì‚° ê¸°ì¤€ ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ
    keyword_cols = [col for col in trend_data.columns if col != "date"]
    keyword_totals = trend_data[keyword_cols].sum().sort_values(ascending=False)
    top_keywords = keyword_totals.head(20).index.tolist()

    trend_data_long = trend_data.melt(id_vars=["date"], var_name="keyword", value_name="count")
    trend_data_top20 = trend_data_long[trend_data_long["keyword"].isin(top_keywords)]

except Exception as e:
    st.error(f"íŠ¸ë Œë“œ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
    st.stop()

#try:
#    df = pd.read_csv(search_results_path, encoding="utf-8-sig")
#    df["full_text"] = df["title"].fillna('') + " " + df["snippet"].fillna('')
#except FileNotFoundError:
#    st.error(f"ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {search_results_path}")
#    st.stop()
    
# íƒ­
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ë¹ˆë„ìˆ˜", "ğŸ•¸ ë„¤íŠ¸ì›Œí¬", "ğŸ” ì—°ê´€ì–´", "ğŸ† ë³´ê³ ì„œ"])

# --- 7.1 ë¹ˆë„ìˆ˜ í†µê³„
with tab1:
    st.subheader("ğŸ“Š ì£¼ê¸°ë³„ í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ í†µê³„")

    trend_df = trend_data.copy()
    trend_df["date"] = trend_df["date"].dt.strftime("%Y-%m-%d")  # ë‚ ì§œ í¬ë§· ì˜ˆì˜ê²Œ

    # 0ì¸ ê°’ ì œê±°ë¥¼ ìœ„í•´ melt í›„ ë‹¤ì‹œ í”¼ë²—
    trend_long = trend_df.melt(id_vars="date", var_name="keyword", value_name="count")
    trend_long = trend_long[trend_long["count"] > 0]  # 0 ë¹ˆë„ ì œê±°

    # ë‚ ì§œ x í‚¤ì›Œë“œ í…Œì´ë¸” êµ¬ì„±
    trend_pivot = trend_long.pivot_table(index="date", columns="keyword", values="count", fill_value=0)

    # keyword ì•ŒíŒŒë²³/í•œê¸€ ìˆœ ì •ë ¬
    trend_pivot = trend_pivot.reindex(sorted(trend_pivot.columns), axis=1)

    st.dataframe(trend_pivot, use_container_width=True)
    
    st.subheader(f"ğŸ“ˆ ë¹ˆë„ìˆ˜ ìƒìœ„ 20 í‚¤ì›Œë“œ íŠ¸ë Œë“œ ì°¨íŠ¸")
    n_cols = 5
    rows = [top_keywords[i:i + n_cols] for i in range(0, len(top_keywords), n_cols)]
    
    for row_keywords in rows:
        cols = st.columns(n_cols)
        for idx, keyword in enumerate(row_keywords):
            with cols[idx]:
                st.markdown(f"**{keyword}**")
                df_kw = trend_data_top20[trend_data_top20["keyword"] == keyword]
    
                chart = alt.Chart(df_kw).mark_line(point=True).encode(
                    x=alt.X('date:T', axis=alt.Axis(labelFontSize=8, titleFontSize=10)),
                    y=alt.Y('count:Q', title='', axis=alt.Axis(labelFontSize=8)),
                    color=alt.value('crimson')
                ).properties(width=220, height=180)
    
                st.altair_chart(chart, use_container_width=False)
    
# --- 7.2 ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„
with tab2:
    st.subheader("ğŸ•¸ ì „ì²´ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ (Top 20 ì¤‘ì‹¬)")

    # ğŸ“Œ ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ ì„ íƒ
    style_option = st.selectbox("ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ì„ ì„ íƒí•˜ì„¸ìš”", ["ì˜ˆì‹œ1 - ê¸°ë³¸", "ì˜ˆì‹œ2 - ê³„ì¸µí˜•", "ì˜ˆì‹œ3 - ëœë¤ ê³ ì •"])

    # ğŸ“Œ ìŠ¤íƒ€ì¼ë³„ Config í”„ë¦¬ì…‹ ì •ì˜
    if style_option == "ì˜ˆì‹œ1 - ê¸°ë³¸":
        config = Config(
            width=900,
            height=700,
            directed=False,
            physics=True,
            hierarchical=False,
            nodeHighlightBehavior=True,
            highlightColor="#FFCC00",
            collapsible=True,
            node={"color": "#00BFFF"},
            edge={"color": "#AAAAAA"},
            layout={"improvedLayout": True}
        )
    elif style_option == "ì˜ˆì‹œ2 - ê³„ì¸µí˜•":
        config = Config(
            width=1000,
            height=700,
            directed=True,
            physics=False,
            hierarchical=True,
            layout={"hierarchical": {"enabled": True, "direction": "LR"}},
            node={"color": "#a29bfe"},
            edge={"color": "#dfe6e9"}
        )
    elif style_option == "ì˜ˆì‹œ3 - ëœë¤ ê³ ì •":
        config = Config(
            width=900,
            height=600,
            physics=False,
            hierarchical=False,
            node={"color": "#6c5ce7"},
            edge={"color": "#b2bec3"},
            layout={"randomSeed": 7}
        )

    # ğŸ” í‚¤ì›Œë“œë³„ ì—°ê²° count í•©ì‚° â†’ Top 20 ì¶”ì¶œ
    keyword_link_count = defaultdict(int)
    for link in report["cooccurrence"]:
        keyword_link_count[link["source"]] += link["count"]
        keyword_link_count[link["target"]] += link["count"]

    top20_keywords = sorted(keyword_link_count.items(), key=lambda x: x[1], reverse=True)[:20]
    top20_keywords = {kw for kw, _ in top20_keywords}

    filtered_links = [
        link for link in report["cooccurrence"]
        if link["source"] in top20_keywords or link["target"] in top20_keywords
    ]

    # ğŸ§© ë…¸ë“œ/ì—£ì§€ êµ¬ì„±
    node_ids = set()
    nodes = []
    edges = []

    for link in filtered_links:
        source, target, count = link['source'], link['target'], link['count']

        if source not in node_ids:
            nodes.append(Node(id=source, label=source, font={"color": "white"}))
            node_ids.add(source)
        if target not in node_ids:
            nodes.append(Node(id=target, label=target, font={"color": "white"}))
            node_ids.add(target)

        edges.append(Edge(source=source, target=target, label=str(count)))

    # ğŸ“Š ê·¸ë˜í”„ ì¶œë ¥
    try:
        agraph(nodes=nodes, edges=edges, config=config)
    except Exception as e:
        st.error(f"ê·¸ë˜í”„ ë Œë”ë§ ì‹¤íŒ¨: {e}")

# --- 7.3 ì—°ê´€ì–´ í†µê³„
with tab3:
    st.subheader("ğŸ” ì „ì²´ ì—°ê´€ì–´ Top 20")

    # count ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    associations_sorted = sorted(report["associations"], key=lambda x: x["count"], reverse=True)[:20]

    # 2ì—´ í‘œì‹œ
    col1, col2 = st.columns(2)
    half = len(associations_sorted) // 2

    for i, assoc in enumerate(associations_sorted):
        text = f"ğŸ”¹ {assoc['term']} ({assoc['count']}íšŒ)"
        if i < half:
            col1.write(text)
        else:
            col2.write(text)

# --- 7.4 Top 20 í‚¤ì›Œë“œ + ê´€ë ¨ ì‚¬ì´íŠ¸
with tab4:
    if summary_type == "ì „ì²´":
        st.subheader("ğŸ†Top 20 í‚¤ì›Œë“œì™€ ê´€ë ¨ ì‚¬ì´íŠ¸")
        
        # ë°ì´í„° ì½ê¸° (full_text ìƒì„± í¬í•¨)
        search_results_path = f"assets/data/{snapshot_dates[-1]}_search_results.csv"
        try:
            df = pd.read_csv(search_results_path, encoding="utf-8-sig")
            df["full_text"] = df["title"].fillna('') + " " + df["snippet"].fillna('')
        except FileNotFoundError:
            st.error(f"ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {search_results_path}")
            st.stop()
        
        # í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ì§‘ê³„
        keyword_counter = {kw: df["full_text"].str.contains(kw, na=False, regex=False).sum() for kw in keywords}
        top_keywords = sorted(keyword_counter.items(), key=lambda x: x[1], reverse=True)[:20]
        
        # ê´€ë ¨ ê¸°ì‚¬ ì •ë¦¬
        keyword_sections = {}
        for kw, _ in top_keywords:
            matched_rows = df[df["full_text"].str.contains(kw, na=False, regex=False)].copy()
            matched_rows = matched_rows[["title", "link", "snippet"]]
            matched_rows["snippet"] = matched_rows["snippet"].str.slice(0, 200)
            keyword_sections[kw] = matched_rows
    
        # ğŸ“ ì—‘ì…€ ë²„í¼ ìƒì„±
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
            for kw, sub_df in keyword_sections.items():
                sheet_name = kw[:31]  # ì‹œíŠ¸ ì´ë¦„ì€ 31ì ì œí•œ
                sub_df.to_excel(writer, index=False, sheet_name=sheet_name)
    
        # ğŸ“¥ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        st.download_button(
            label="ğŸ“¥ í‚¤ì›Œë“œë³„ ê´€ë ¨ ê¸°ì‚¬ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            data=output.getvalue(),
            file_name=f"{snapshot_dates[-1]}_top20_keywords.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    
        # ğŸ‘ï¸ ê¸°ì¡´ UIë„ ìœ ì§€
        for idx, (kw, count) in enumerate(top_keywords, 1):
            with st.expander(f"**{idx}. {kw}** ({count}íšŒ ë“±ì¥)", expanded=False):
                for _, row in keyword_sections[kw].iterrows():
                    st.markdown(f"- [{row['title']}]({row['link']})")
                    st.caption(f"{row['snippet'][:80]}...")

