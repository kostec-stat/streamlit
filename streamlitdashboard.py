# -*- coding: utf-8 -*-
# Author : Dr. Songhee Kang
# Description : KOSTEC stat visualizer

import streamlit as st
import pandas as pd
import json
import altair as alt
import networkx as nx
from streamlit_agraph import agraph, Node, Edge, Config
import os

# --- 1. ì„¤ì • (ê°€ì¥ ë¨¼ì €)
st.set_page_config(page_title="ğŸ“ˆ í‚¤ì›Œë“œ ëŒ€ì‹œë³´ë“œ", layout="wide")
# --- 2. CSS ì ìš©
def local_css(file_name):
    with open(file_name, "r", encoding="utf-8") as f:
        css_content = f.read()
    st.markdown(f"<style>{css_content}</style>", unsafe_allow_html=True)

# assets/css í´ë”ì˜ main.cssë¥¼ ì½ì–´ì˜¤ê¸°
local_css("assets/css/main.css")
# --- 3. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
def load_keywords(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]

def load_json(path):
    with open(path, encoding='utf-8-sig') as f:
        return json.load(f)

# í‚¤ì›Œë“œ, ìŠ¤ëƒ…ìƒ· ë‚ ì§œ
keywords = load_keywords("assets/input/keywords.txt")
snapshot_dates = ['20250429']

# --- 4. ì‚¬ì´ë“œë°”
selected_keyword = st.sidebar.selectbox("ê´€ì‹¬ í‚¤ì›Œë“œ ì„ íƒ", keywords)
selected_snapshot = st.sidebar.selectbox("ìŠ¤ëƒ…ìƒ· ë‚ ì§œ ì„ íƒ", snapshot_dates)

# --- 5. ë©”ì¸ ëŒ€ì‹œë³´ë“œ
st.title("ğŸ“ˆ ì£¼ê°„ í‚¤ì›Œë“œ ëŒ€ì‹œë³´ë“œ")
    
# --- 6. ë°ì´í„° ê²½ë¡œ ì„¤ì •
report_path = f"assets/reports/{selected_keyword}_{selected_snapshot}.json"
trend_path = f"assets/data/{selected_snapshot}_trend_summary.json"
    
try:
    report = load_json(report_path)
except FileNotFoundError:
    st.error("ë³´ê³ ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()
    
# íƒ­
tab1, tab2, tab3 = st.tabs(["ğŸ“Š ë¹ˆë„ìˆ˜", "ğŸ•¸ ë„¤íŠ¸ì›Œí¬", "ğŸ” ì—°ê´€ì–´"])

# --- 7.1 ë¹ˆë„ìˆ˜ í†µê³„
with tab1:
    st.subheader(f"ğŸ“Š {selected_keyword} ë¹ˆë„ìˆ˜ í†µê³„")
    freq_df = pd.DataFrame(report["frequency_stats"])
    selected_freq_df = freq_df[freq_df["keyword"] == selected_keyword]
    st.dataframe(selected_freq_df)

    st.subheader(f"ğŸ“ˆ {selected_keyword} íŠ¸ë Œë“œ ì°¨íŠ¸")
    trend_data_long = trend_data.melt(id_vars=["date"], var_name="keyword", value_name="count")
    trend_data_filtered = trend_data_long[trend_data_long["keyword"] == selected_keyword]

    chart = alt.Chart(trend_data_filtered).mark_line(point=True).encode(
        x='date:T',
        y=alt.Y('count:Q', title='ë¹ˆë„ìˆ˜'),
        color=alt.value('teal')
    )
    st.altair_chart(chart, use_container_width=True)

    # --- 7.2 ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„
with tab2:
    st.subheader(f"ğŸ•¸ {selected_keyword} ê´€ë ¨ ë„¤íŠ¸ì›Œí¬")
    try:
        node_ids = set()
        nodes = []
        edges = []

        for link in report["cooccurrence"]:
            if selected_keyword in (link['source'], link['target']):
                source, target, count = link['source'], link['target'], link['count']

                if source not in node_ids:
                    nodes.append(Node(id=source, label=source, font={"color": "white"}))
                    node_ids.add(source)
                if target not in node_ids:
                    nodes.append(Node(id=target, label=target, font={"color": "white"}))
                    node_ids.add(target)

                edges.append(Edge(source=source, target=target, label=str(count)))

        config = Config(width=800, height=600, directed=False, physics=True, hierarchical=False)
        agraph(nodes=nodes, edges=edges, config=config)
    except Exception as e:
        st.error(f"ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ë¡œë”© ì‹¤íŒ¨: {e}")

    # --- 7.3 ì—°ê´€ì–´ í†µê³„
with tab3:
    st.subheader(f"ğŸ” {selected_keyword} ì—°ê´€ì–´ í†µê³„")
    for assoc in report["associations"]:
        st.write(f"ğŸ”¹ {assoc['term']} ({assoc['count']}íšŒ)")

# --- 5. í•˜ë‹¨(í‘¸í„°) Top 20 í‚¤ì›Œë“œ + ê´€ë ¨ ì‚¬ì´íŠ¸
st.divider()
st.subheader("ğŸ† Top 20 í‚¤ì›Œë“œ ë° ê´€ë ¨ ì‚¬ì´íŠ¸")

# ë°ì´í„° ì½ê¸° (full_text ìƒì„± í¬í•¨)
search_results_path = f"assets/data/{selected_snapshot}_search_results.csv"
try:
    df = pd.read_csv(search_results_path, encoding="utf-8-sig")
    df["full_text"] = df["title"].fillna('') + " " + df["snippet"].fillna('')
except FileNotFoundError:
    st.error(f"ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {search_results_path}")
    st.stop()

# í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ì§‘ê³„
keyword_counter = {kw: df["full_text"].str.contains(kw, na=False, regex=False).sum() for kw in keywords}
top_keywords = sorted(keyword_counter.items(), key=lambda x: x[1], reverse=True)[:20]

# í•˜ë‹¨ íŒ¨ë„ í‘œì‹œ
for idx, (kw, count) in enumerate(top_keywords, 1):
    with st.expander(f"**{idx}. {kw}** ({count}íšŒ ë“±ì¥)", expanded=False):
        matched_rows = df[df["full_text"].str.contains(kw, na=False, regex=False)]
        for _, row in matched_rows.iterrows():
            st.markdown(f"- [{row['title']}]({row['link']})")
            st.caption(f"{row['snippet'][:80]}...")
