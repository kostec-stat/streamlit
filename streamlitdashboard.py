#-*- coding: utf-8 -*-
#   Author : Dr. Songhee Kang.
#   Email : dellabee@tukorea.ac.kr
#   Description : KOSTEC stat visualizer
#   Version : 1.0.0
#   History : 1.0.0 - 2025. 04. 29. ìµœì´ˆ ì‘ì„±

# streamlit_dashboard.py

import streamlit as st
import pandas as pd
import json
import altair as alt
import networkx as nx
from pyvis.network import Network
import streamlit.components.v1 as components
from streamlit_agraph import agraph, Node, Edge, Config
import os

# í‚¤ì›Œë“œ, ìŠ¤ëƒ…ìƒ· ë‚ ì§œ ë¦¬ìŠ¤íŠ¸
keywords = []
# 1. í‚¤ì›Œë“œ ë¡œë”©
def load_keywords(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        keywords = [line.strip() for line in f if line.strip()]
    return keywords

keywords = load_keywords("assets/input/keywords.txt")  # í‚¤ì›Œë“œ íŒŒì¼ ê²½ë¡œ ìˆ˜ì •
snapshot_dates = ['20250429']

# Streamlit App ì‹œì‘
st.set_page_config(page_title="ğŸ“ˆ í‚¤ì›Œë“œ ëŒ€ì‹œë³´ë“œ", layout="wide")
col_main, col_side = st.columns([3, 1])
with col_main:
    st.title("ğŸ“ˆ ì£¼ê°„ í‚¤ì›Œë“œ ëŒ€ì‹œë³´ë“œ")
    
    # ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œì™€ ë‚ ì§œ ì„ íƒ
    selected_keyword = st.sidebar.selectbox("ê´€ì‹¬ í‚¤ì›Œë“œ ì„ íƒ", keywords)
    selected_snapshot = st.sidebar.selectbox("ìŠ¤ëƒ…ìƒ· ë‚ ì§œ ì„ íƒ", snapshot_dates)
    
    # ì„ íƒì— ë”°ë¼ JSON íŒŒì¼ ê²½ë¡œ ê²°ì •
    report_path = f"assets/reports/{selected_keyword}_{selected_snapshot}.json"
    trend_path = f"assets/data/{selected_snapshot}_trend_summary.json"
    
    # ë°ì´í„° ë¡œë”©
    @st.cache_data
    def load_report(path):
        with open(path, encoding='utf-8-sig') as f:
            return json.load(f)
    
    try:
        report = load_report(report_path)
    except FileNotFoundError:
        st.error("ë³´ê³ ì„œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜", "ğŸ•¸ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬", "ğŸ” ì—°ê´€ì–´ í†µê³„", "ğŸ† Top 20 í‚¤ì›Œë“œ"])
    
    # 1. í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ í†µê³„
    with tab1:
        st.subheader("ğŸ“Š í‚¤ì›Œë“œë³„ ë¹ˆë„ìˆ˜ í†µê³„")
        
        freq_df = pd.DataFrame(report["frequency_stats"])
        st.dataframe(freq_df)
        
        st.subheader("ğŸ“ˆ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ì°¨íŠ¸")
        try:
            with open(trend_path, encoding='utf-8-sig') as f:
                trend_json = json.load(f)
        
            trend_data = pd.DataFrame(trend_json["trend_data"])
        
            # long formatìœ¼ë¡œ ë³€í™˜ (date, keyword, count í˜•íƒœ)
            trend_data_long = trend_data.melt(id_vars=["date"], var_name="keyword", value_name="count")
        
            chart = alt.Chart(trend_data_long).mark_line(point=True).encode(
                x='date:T',
                y=alt.Y('count:Q', title='ë¹ˆë„ìˆ˜'),
                color='keyword:N'
            )
            st.altair_chart(chart, use_container_width=True)
        except Exception as e:
            st.error(f"íŠ¸ë Œë“œ ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    
    
    # 2. í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬
    with tab2:
        st.subheader("ğŸ•¸ í‚¤ì›Œë“œ ë™ì‹œì¶œí˜„ ë„¤íŠ¸ì›Œí¬ (Graph)")
        try:
            node_ids = set()
            nodes = []
            edges = []
            background_color = "black"
            font_color = "white"
            # ë…¸ë“œë¥¼ ì¤‘ë³µ ì—†ì´ ë§Œë“¤ê¸°
            for link in report["cooccurrence"]:
                source = link['source']
                target = link['target']
                count = link['count']
    
                if source not in node_ids:
                    nodes.append(Node(id=source, label=source))
                    node_ids.add(source)
    
                if target not in node_ids:
                    nodes.append(Node(id=target, label=target))
                    node_ids.add(target)
    
                edges.append(Edge(source=source, target=target, label=str(count)))
    
            config = Config(
                width=800,
                height=600,
                directed=False,
                physics=True,
                hierarchical=False
            )
    
            agraph(nodes=nodes, edges=edges, config=config)
    
        except Exception as e:
            st.error(f"ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ë¡œë”© ì‹¤íŒ¨: {e}")
    # 3. ì—°ê´€ì–´ í†µê³„
    with tab3:
        st.subheader("ğŸ” í‚¤ì›Œë“œ ì—°ê´€ì–´ í†µê³„")
        for assoc in report["associations"]:
            st.write(f"ğŸ”¹ {assoc['term']} ({assoc['count']}íšŒ)")
            
# Top 20 í‚¤ì›Œë“œ (ì˜¤ë¥¸ìª½ íŒ¨ë„)
with col_side:
    st.header("ğŸ† Top 20 í‚¤ì›Œë“œ")



# CSV íŒŒì¼ ì½ê¸°
    df = pd.read_csv(f"assets/data/{selected_snapshot}_search_results.csv", encoding="utf-8-sig")
    
    # title + snippet í•©ì¹˜ê¸° (full_text ì»¬ëŸ¼ ë§Œë“¤ê¸°)
    df["full_text"] = df["title"].fillna('') + " " + df["snippet"].fillna('')
    # 1. í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ì§‘ê³„
    keyword_counter = {}
    for kw in keywords:
        keyword_counter[kw] = df["full_text"].str.contains(kw, na=False, regex=False).sum()

    # 2. ë¹ˆë„ìˆ˜ ê¸°ì¤€ ìƒìœ„ 20ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ
    top_keywords = sorted(keyword_counter.items(), key=lambda x: x[1], reverse=True)[:20]

    for idx, (kw, count) in enumerate(top_keywords, 1):
        st.markdown(f"**{idx}. {kw}** ({count}íšŒ ë“±ì¥)")

        # 3. ê´€ë ¨ ì‚¬ì´íŠ¸(title, link, snippet) ë¦¬ìŠ¤íŠ¸
        matched_rows = df[df["full_text"].str.contains(kw, na=False)]
        for _, row in matched_rows.iterrows():
            st.markdown(f"- [{row['title']}]({row['link']})")
            st.caption(f"{row['snippet'][:80]}...")  # snippetì„ ì§§ê²Œ ìš”ì•½
        st.divider()
